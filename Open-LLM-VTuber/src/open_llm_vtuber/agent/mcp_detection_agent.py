"""
LangChain-based MCP Detection Agent
æ™ºèƒ½æ£€æµ‹ç”¨æˆ·æŸ¥è¯¢æ˜¯å¦éœ€è¦MCPå·¥å…·è°ƒç”¨ï¼Œæ›¿ä»£ç¡¬ç¼–ç å…³é”®è¯æ£€æµ‹
"""

from typing import Dict, Any, Optional, List, Union
from pydantic import BaseModel, Field
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.language_models.base import BaseLanguageModel
from langchain_core.messages import BaseMessage, AIMessage
from langchain_core.callbacks.manager import CallbackManagerForLLMRun
from langchain_core.outputs import LLMResult
from loguru import logger
import json


class StatelessLLMAdapter(BaseLanguageModel):
    """
    å°†StatelessLLMInterfaceé€‚é…ä¸ºLangChain BaseLanguageModel
    """

    def __init__(self, stateless_llm):
        """åˆå§‹åŒ–é€‚é…å™¨

        Args:
            stateless_llm: StatelessLLMInterfaceå®ä¾‹
        """
        super().__init__()
        self.stateless_llm = stateless_llm

    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> LLMResult:
        """åŒæ­¥ç”Ÿæˆï¼ˆä¸æ¨èä½¿ç”¨ï¼‰"""
        raise NotImplementedError("Use async methods instead")

    async def _agenerate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> LLMResult:
        """å¼‚æ­¥ç”Ÿæˆ"""
        try:
            # å°†LangChainæ¶ˆæ¯è½¬æ¢ä¸ºæ–‡æœ¬
            text_content = ""
            for message in messages:
                if hasattr(message, 'content'):
                    text_content += str(message.content) + "\n"
                else:
                    text_content += str(message) + "\n"

            # è°ƒç”¨StatelessLLM
            if hasattr(self.stateless_llm, 'ainvoke'):
                response = await self.stateless_llm.ainvoke(text_content.strip())
            elif hasattr(self.stateless_llm, 'invoke'):
                response = self.stateless_llm.invoke(text_content.strip())
            else:
                # å°è¯•ç›´æ¥è°ƒç”¨
                response = await self.stateless_llm(text_content.strip())

            # æå–å“åº”å†…å®¹
            if hasattr(response, 'content'):
                response_text = response.content
            elif hasattr(response, 'text'):
                response_text = response.text
            else:
                response_text = str(response)

            # åŒ…è£…ä¸ºLangChainæ ¼å¼
            from langchain_core.outputs import Generation
            generation = Generation(text=response_text)
            return LLMResult(generations=[[generation]])

        except Exception as e:
            logger.error(f"StatelessLLMé€‚é…å™¨è°ƒç”¨å¤±è´¥: {e}")
            # è¿”å›ç©ºç»“æœ
            from langchain_core.outputs import Generation
            generation = Generation(text=f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return LLMResult(generations=[[generation]])

    @property
    def _llm_type(self) -> str:
        """è¿”å›LLMç±»å‹"""
        return "stateless_llm_adapter"


class MCPAnalysisResult(BaseModel):
    """MCPéœ€æ±‚åˆ†æç»“æœçš„ç»“æ„åŒ–è¾“å‡º"""
    needs_mcp: bool = Field(description="æ˜¯å¦éœ€è¦MCPå·¥å…·è°ƒç”¨")
    confidence: float = Field(description="ç½®ä¿¡åº¦ (0.0-1.0)", ge=0.0, le=1.0)
    reasoning: str = Field(description="åˆ†ææ¨ç†è¿‡ç¨‹")
    suggested_tools: List[str] = Field(default=[], description="å»ºè®®ä½¿ç”¨çš„å·¥å…·ç±»å‹")
    task_type: str = Field(description="ä»»åŠ¡ç±»å‹: information_query, action_request, casual_chat")
    urgency: str = Field(description="ç´§æ€¥ç¨‹åº¦: high, medium, low")


class MCPDetectionAgent:
    """LangChain-basedæ™ºèƒ½MCPæ£€æµ‹ä»£ç†"""

    def __init__(self, llm: Union[BaseLanguageModel, Any]):
        # è‡ªåŠ¨é€‚é…StatelessLLM
        if not isinstance(llm, BaseLanguageModel):
            logger.debug("ğŸ”§ MCPDetectionAgent: ä½¿ç”¨StatelessLLMé€‚é…å™¨")
            self.llm = StatelessLLMAdapter(llm)
        else:
            self.llm = llm
        self.parser = JsonOutputParser(pydantic_object=MCPAnalysisResult)
        self.prompt = self._create_detection_prompt()
        self.chain = self.prompt | self.llm | self.parser

    def _create_detection_prompt(self) -> ChatPromptTemplate:
        """åˆ›å»ºMCPæ£€æµ‹æç¤ºè¯"""
        format_instructions = self.parser.get_format_instructions()

        prompt_template = """You are an intelligent task analysis assistant that needs to determine whether user queries require calling MCP (Model Context Protocol) tools.

**Currently Available Tools (11 total):**

ğŸŒ¤ï¸ **Weather Tools (6)** - US Weather Information
- get_current_weather: Get current weather for a US location
- get_weather_forecast: Get daily weather forecast (up to 7 days)
- get_hourly_forecast: Get hourly weather forecast
- get_weather_alerts: Get active weather alerts for a location
- find_weather_stations: Find nearby weather observation stations
- get_local_time: Get current local time for a location

ğŸµ **Music Generation (1)** - AI Music Creation
- suno-generate-music-with-stream: Generate music with Suno AI, supports streaming download

ğŸ¨ **Image Generation Tools (3)** - AI Image Creation & Editing
- generate_image: Generate images using AI models (DALL-E, Gemini, etc.)
- edit_image: Edit existing images with AI
- create_image_variation: Create variations of an existing image

ğŸ” **Search Tool (1)** - MCP Service Discovery
- search_mcp_tools: Search and discover additional MCP tools from the marketplace

User query: "{user_input}"

Please analyze this query and provide a structured judgment result.

**Analysis Guidelines:**

1. **Weather Queries** â†’ Use weather tools
   - Keywords: "å¤©æ°”", "weather", "æ¸©åº¦", "temperature", "é¢„æŠ¥", "forecast", "è­¦æŠ¥", "alert"
   - Locations: Must be US cities (New York, Los Angeles, Chicago, etc.)
   - Confidence: 0.9+ if clear weather request

2. **Image Generation** â†’ Use image tools
   - Keywords: "ç”Ÿæˆå›¾ç‰‡", "ç”»ä¸€å¼ ", "åˆ›å»ºå›¾åƒ", "draw", "generate image", "create picture"
   - Art styles: "æ²¹ç”»", "å¡é€š", "å†™å®", "åŠ¨æ¼«", "oil painting", "cartoon", "realistic"
   - Actions: "ç¼–è¾‘å›¾ç‰‡", "ä¿®æ”¹å›¾ç‰‡", "å›¾ç‰‡å˜ä½“", "edit image", "image variation"
   - Confidence: 0.9+ for generation, 0.85+ for editing

3. **Music Generation** â†’ Use music tool
   - Keywords: "ç”ŸæˆéŸ³ä¹", "åˆ›ä½œéŸ³ä¹", "generate music", "create song", "ä½œæ›²", "compose"
   - Genres: "æµè¡Œ", "å¤å…¸", "æ‘‡æ»š", "pop", "classical", "rock"
   - Confidence: 0.9+ for clear music requests

4. **Tool Discovery** â†’ Use search tool
   - Keywords: "æŸ¥æ‰¾å·¥å…·", "æœç´¢å·¥å…·", "æœ‰ä»€ä¹ˆå·¥å…·", "find tools", "search tools", "available tools"
   - Confidence: 0.85+

5. **Casual Chat** â†’ No tools needed
   - Greetings, general questions, philosophical discussions
   - Confidence: 0.1-0.3

**Output Format:**
{format_instructions}

Please ensure the output is in valid JSON format."""

        return ChatPromptTemplate.from_template(prompt_template)

    async def analyze_user_input(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> MCPAnalysisResult:
        """
        åˆ†æç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦MCPå·¥å…·

        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            MCPAnalysisResult: ç»“æ„åŒ–çš„åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ” [MCPDetection] å¼€å§‹åˆ†æç”¨æˆ·è¾“å…¥: {user_input[:100]}...")

            # å‡†å¤‡è¾“å…¥æ•°æ®
            chain_input = {
                "user_input": user_input,
                "format_instructions": self.parser.get_format_instructions()
            }

            # è°ƒç”¨LangChainé“¾
            result = await self.chain.ainvoke(chain_input)

            # ç¡®ä¿ç»“æœæ˜¯MCPAnalysisResultå¯¹è±¡
            if isinstance(result, dict):
                analysis_result = MCPAnalysisResult(**result)
            else:
                analysis_result = result

            logger.info(f"ğŸ¯ [MCPDetection] åˆ†æå®Œæˆ: needs_mcp={analysis_result.needs_mcp}, confidence={analysis_result.confidence}")
            logger.debug(f"ğŸ¯ [MCPDetection] æ¨ç†è¿‡ç¨‹: {analysis_result.reasoning}")

            return analysis_result

        except Exception as e:
            logger.error(f"âŒ [MCPDetection] åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„ä¿å®ˆç»“æœ
            return MCPAnalysisResult(
                needs_mcp=False,
                confidence=0.0,
                reasoning=f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}",
                suggested_tools=[],
                task_type="casual_chat",
                urgency="low"
            )

    def should_trigger_mcp(self, analysis: MCPAnalysisResult, threshold: float = 0.7) -> bool:
        """
        åŸºäºåˆ†æç»“æœåˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘MCP

        Args:
            analysis: MCPåˆ†æç»“æœ
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            bool: æ˜¯å¦åº”è¯¥è§¦å‘MCP
        """
        return analysis.needs_mcp and analysis.confidence >= threshold


class LangChainTaskAnalyzer:
    """LangChain-basedä»»åŠ¡å®Œæˆåº¦åˆ†æ"""

    def __init__(self, llm: Union[BaseLanguageModel, Any]):
        # è‡ªåŠ¨é€‚é…StatelessLLM
        if not isinstance(llm, BaseLanguageModel):
            logger.debug("ğŸ”§ LangChainTaskAnalyzer: ä½¿ç”¨StatelessLLMé€‚é…å™¨")
            self.llm = StatelessLLMAdapter(llm)
        else:
            self.llm = llm
        self.completion_prompt = self._create_completion_prompt()

    def _create_completion_prompt(self) -> ChatPromptTemplate:
        """åˆ›å»ºä»»åŠ¡å®Œæˆåº¦åˆ†ææç¤ºè¯"""
        prompt_template = """You are a task completion analysis assistant. Please analyze whether the current tool execution results fully satisfy the user's query requirements.

User's original query: "{user_query}"
Executed tool: {tool_name}
Tool execution result: {tool_result}

**Analysis Rules (by query type):**

**Weather Query**: If user queries weather information, usually one call can get complete results
- Contains temperature, weather conditions, city information â†’ is_complete: true, completion_percentage: 1.0
- Only basic information but meets query needs â†’ completion_percentage: 0.9+

**Ticket Query**: If user queries train/ticket information
- Only station codes/station information â†’ is_complete: false, completion_percentage: 0.2, suggested_next_tools: ["get-tickets"]
- Contains ticket prices but lacks availability information â†’ completion_percentage: 0.7, suggested_next_tools: ["get-tickets"]
- Contains complete ticket information (prices, availability, schedule times, etc.) â†’ completion_percentage: 1.0, suggested_next_tools: []

**Image Generation Query**: If user requests image creation or artwork
- Successfully generated image with proper response format including base64 data â†’ is_complete: true, completion_percentage: 1.0
- Generated image but with basic metadata only â†’ completion_percentage: 0.9
- Tool execution started but no image data returned â†’ is_complete: false, completion_percentage: 0.3, suggested_next_tools: ["generate_image", "create_image"]
- Error in generation process â†’ completion_percentage: 0.1, suggested_next_tools: ["generate_image"]

**Music Generation Query**: If user requests music or audio creation
- Successfully generated music with streaming URL or file â†’ is_complete: true, completion_percentage: 1.0
- Generated music metadata but no playable content â†’ completion_percentage: 0.4, suggested_next_tools: ["suno-generate-music"]

**General Information Query**:
- Completely answers user's question â†’ completion_percentage: 1.0
- Partial answer but has practical value â†’ completion_percentage: 0.6-0.9
- Irrelevant or useless information â†’ completion_percentage: 0.1-0.3

**Key Evaluation Principles:**
1. First determine the query type, then apply corresponding rules
2. Focus on evaluating whether the user's specific needs are resolved
3. For simple and clear queries (like weather), don't over-require additional information

Please respond in JSON format:
{{
    "is_complete": boolean,
    "completion_percentage": float (0.0-1.0),
    "missing_aspects": [string],
    "suggested_next_tools": [string],
    "quality_score": float (0.0-1.0),
    "user_friendly_response": "If completion_percentage >= 1.0, please provide a user-friendly final answer directly (natural and friendly language, highlight key information, concise and clear)"
}}

**Important**:
1. is_complete must be consistent with completion_percentage:
   - completion_percentage >= 1.0 â†’ is_complete: true
   - completion_percentage < 1.0 â†’ is_complete: false
2. If is_complete is false, please specify the tools that might be needed in suggested_next_tools
3. Based on the user query's actual needs and current result deficiencies, intelligently recommend the most relevant tools"""

        return ChatPromptTemplate.from_template(prompt_template)

    async def analyze_task_completion(
        self,
        user_query: str,
        tool_name: str,
        tool_result: Any
    ) -> Dict[str, Any]:
        """
        åˆ†æä»»åŠ¡å®Œæˆæƒ…å†µ

        Args:
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            tool_name: æ‰§è¡Œçš„å·¥å…·åç§°
            tool_result: å·¥å…·æ‰§è¡Œç»“æœ

        Returns:
            Dict: ä»»åŠ¡å®Œæˆåº¦åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ“Š [TaskAnalyzer] åˆ†æä»»åŠ¡å®Œæˆåº¦: {user_query[:50]}...")

            # å‡†å¤‡å·¥å…·ç»“æœçš„å­—ç¬¦ä¸²è¡¨ç¤º
            result_str = str(tool_result)[:1000]  # é™åˆ¶é•¿åº¦é¿å…tokenè¿‡å¤š

            chain_input = {
                "user_query": user_query,
                "tool_name": tool_name,
                "tool_result": result_str
            }

            # åˆ›å»ºä¸´æ—¶é“¾
            chain = self.completion_prompt | self.llm | JsonOutputParser()
            result = await chain.ainvoke(chain_input)

            logger.info(f"âœ… [TaskAnalyzer] å®Œæˆåº¦åˆ†æç»“æœ: {result.get('completion_percentage', 0.0)}")

            return result

        except Exception as e:
            logger.error(f"âŒ [TaskAnalyzer] åˆ†æå¤±è´¥: {e}")
            return {
                "is_complete": True,  # ä¿å®ˆç­–ç•¥ï¼Œé¿å…æ— é™å¾ªç¯
                "completion_percentage": 0.5,
                "missing_aspects": [],
                "suggested_next_tools": [],
                "quality_score": 0.5
            }


class LangChainMCPOrchestrator:
    """LangChain-based MCPå·¥å…·ç¼–æ’å™¨"""

    def __init__(self, llm: Union[BaseLanguageModel, Any]):
        # è‡ªåŠ¨é€‚é…StatelessLLM
        if not isinstance(llm, BaseLanguageModel):
            logger.debug("ğŸ”§ LangChainMCPOrchestrator: ä½¿ç”¨StatelessLLMé€‚é…å™¨")
            adapted_llm = StatelessLLMAdapter(llm)
        else:
            adapted_llm = llm

        self.detection_agent = MCPDetectionAgent(adapted_llm)
        self.task_analyzer = LangChainTaskAnalyzer(adapted_llm)
        self.max_iterations = 3  # é˜²æ­¢æ— é™å¾ªç¯

    async def should_use_mcp(self, user_input: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨MCPå·¥å…·

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            Dict: åŒ…å«åˆ¤æ–­ç»“æœå’Œåˆ†æä¿¡æ¯
        """
        try:
            # ä½¿ç”¨LangChainè¿›è¡Œæ™ºèƒ½åˆ†æ
            analysis = await self.detection_agent.analyze_user_input(user_input, context)

            # åŸºäºç½®ä¿¡åº¦åˆ¤æ–­
            should_use = self.detection_agent.should_trigger_mcp(analysis, threshold=0.7)

            return {
                "should_use_mcp": should_use,
                "analysis": analysis.model_dump(),
                "confidence": analysis.confidence,
                "reasoning": analysis.reasoning,
                "suggested_tools": analysis.suggested_tools
            }

        except Exception as e:
            logger.error(f"âŒ [MCPOrchestrator] MCPåˆ¤æ–­å¤±è´¥: {e}")
            # è¿”å›ä¿å®ˆç»“æœ
            return {
                "should_use_mcp": False,
                "analysis": {},
                "confidence": 0.0,
                "reasoning": f"åˆ¤æ–­è¿‡ç¨‹å‡ºé”™: {str(e)}",
                "suggested_tools": []
            }

    async def analyze_iteration_need(
        self,
        user_query: str,
        completed_tools: List[Dict[str, Any]],
        iteration_count: int = 0
    ) -> Dict[str, Any]:
        """
        åˆ†ææ˜¯å¦éœ€è¦ç»§ç»­è¿­ä»£ä½¿ç”¨æ›´å¤šå·¥å…·

        Args:
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            completed_tools: å·²å®Œæˆçš„å·¥å…·åˆ—è¡¨
            iteration_count: å½“å‰è¿­ä»£æ¬¡æ•°

        Returns:
            Dict: è¿­ä»£éœ€æ±‚åˆ†æç»“æœ
        """
        try:
            # é˜²æ­¢æ— é™å¾ªç¯
            if iteration_count >= self.max_iterations:
                logger.warning(f"âš ï¸ [MCPOrchestrator] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {self.max_iterations}")
                return {
                    "needs_more_tools": False,
                    "reason": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶"
                }

            if not completed_tools:
                return {
                    "needs_more_tools": False,
                    "reason": "æ²¡æœ‰å·²å®Œæˆçš„å·¥å…·"
                }

            # åˆ†ææœ€åä¸€ä¸ªå·¥å…·çš„å®Œæˆæƒ…å†µ
            last_tool = completed_tools[-1]
            tool_name = last_tool.get("name", "unknown")
            tool_result = last_tool.get("result", "")

            # è°ƒè¯•ï¼šæ‰“å°ä¼ å…¥çš„å‚æ•°
            logger.debug(f"ğŸ” [TaskAnalyzer DEBUG] user_query: {user_query}")
            logger.debug(f"ğŸ” [TaskAnalyzer DEBUG] tool_name: {tool_name}")
            logger.debug(f"ğŸ” [TaskAnalyzer DEBUG] tool_result: {str(tool_result)[:200]}...")

            completion_analysis = await self.task_analyzer.analyze_task_completion(
                user_query, tool_name, tool_result
            )

            # åŸºäºå®Œæˆåº¦åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šå·¥å…·
            is_complete = completion_analysis.get("is_complete", True)
            completion_percentage = completion_analysis.get("completion_percentage", 1.0)

            needs_more = not is_complete and completion_percentage < 0.8

            # è°ƒè¯•ï¼šè¯¦ç»†è®°å½•åˆ¤æ–­è¿‡ç¨‹
            logger.info(f"ğŸ” [å®Œæˆåº¦åˆ¤æ–­] is_complete: {is_complete}, completion_percentage: {completion_percentage}, needs_more: {needs_more}")

            return {
                "needs_more_tools": needs_more,
                "completion_analysis": completion_analysis,
                "iteration_count": iteration_count,
                "reason": f"ä»»åŠ¡å®Œæˆåº¦: {completion_percentage:.1%}"
            }

        except Exception as e:
            logger.error(f"âŒ [MCPOrchestrator] è¿­ä»£åˆ†æå¤±è´¥: {e}")
            return {
                "needs_more_tools": False,
                "reason": f"åˆ†æå¤±è´¥: {str(e)}"
            }


# å•ä¾‹å®ä¾‹ï¼Œä¾›å¤–éƒ¨è°ƒç”¨
_mcp_orchestrator: Optional[LangChainMCPOrchestrator] = None

def get_mcp_orchestrator(llm: Union[BaseLanguageModel, Any]) -> LangChainMCPOrchestrator:
    """è·å–MCPç¼–æ’å™¨å•ä¾‹å®ä¾‹

    Args:
        llm: LangChain BaseLanguageModel æˆ– StatelessLLMInterface

    Returns:
        LangChainMCPOrchestratorå®ä¾‹
    """
    global _mcp_orchestrator
    if _mcp_orchestrator is None:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é€‚é…å™¨
        if not isinstance(llm, BaseLanguageModel):
            # å‡è®¾æ˜¯StatelessLLMInterfaceï¼Œä½¿ç”¨é€‚é…å™¨
            logger.info("ğŸ”§ æ£€æµ‹åˆ°StatelessLLMï¼Œä½¿ç”¨é€‚é…å™¨è½¬æ¢ä¸ºLangChainæ ¼å¼")
            adapted_llm = StatelessLLMAdapter(llm)
        else:
            adapted_llm = llm

        _mcp_orchestrator = LangChainMCPOrchestrator(adapted_llm)
    return _mcp_orchestrator