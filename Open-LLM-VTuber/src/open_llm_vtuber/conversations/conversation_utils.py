import asyncio
import re
from typing import Optional, Union, Any, List, Dict
import numpy as np
import json
from loguru import logger

from ..message_handler import message_handler
from .types import WebSocketSend, BroadcastContext
from .tts_manager import TTSTaskManager
from .global_tts_manager import global_tts_manager, TTSPriority
from ..agent.output_types import SentenceOutput, AudioOutput
from ..agent.input_types import BatchInput, TextData, ImageData, TextSource, ImageSource
from ..asr.asr_interface import ASRInterface
from ..live2d_model import Live2dModel
from ..tts.tts_interface import TTSInterface
from ..utils.stream_audio import prepare_audio_payload
from ..service_context import ServiceContext


# Convert class methods to standalone functions
def create_batch_input(
        input_text: str,
        images: Optional[List[Dict[str, Any]]],
        from_name: str,
) -> BatchInput:
    """Create batch input for agent processing"""
    return BatchInput(
        texts=[
            TextData(source=TextSource.INPUT, content=input_text, from_name=from_name)
        ],
        images=[
            ImageData(
                source=ImageSource(img["source"]),
                data=img["data"],
                mime_type=img["mime_type"],
            )
            for img in (images or [])
        ]
        if images is not None and (isinstance(images, list) and len(images) > 0)
        else None,
    )


async def process_agent_output(
        output: Union[AudioOutput, SentenceOutput],
        character_config: Any,
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
        tts_manager: TTSTaskManager,
        translate_engine: Optional[Any] = None,
        client_uid: str = None,
        tts_priority: TTSPriority = TTSPriority.NORMAL,
) -> str:
    """Process agent output with character information and optional translation"""
    output.display_text.name = character_config.character_name
    output.display_text.avatar = character_config.avatar

    full_response = ""
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨
        if hasattr(output, "tool_calls") and output.tool_calls:
            logger.info(f"Processing tool calls: {output.tool_calls}")
            for tool_call in output.tool_calls:
                tool_name = tool_call.get("name")
                tool_args = tool_call.get("arguments")
                logger.info(f"Tool call: {tool_name} with args: {tool_args}")
                # å·¥å…·è°ƒç”¨ç»“æœä¼šåœ¨åç»­çš„è¾“å‡ºä¸­è¿”å›
                # å¯¹äºsearch_similar_memorieså·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè®©å®ƒç›´æ¥æ˜¾ç¤ºç»“æœ
                if tool_name == "search_similar_memories":
                    # ä¸æ˜¾ç¤ºå·¥å…·è°ƒç”¨æç¤ºï¼Œç›´æ¥ç­‰å¾…å·¥å…·ç»“æœ
                    pass
                else:
                    full_response += f"[è°ƒç”¨å·¥å…·: {tool_name}]\n"

        # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨ç»“æœ
        if hasattr(output, "tool_output") and output.tool_output is not None:
            logger.info(f"Processing tool output: {output.tool_output}")
            tool_name = output.tool_output.get("name", "unknown_tool")
            tool_result = output.tool_output.get("result", "")
            logger.info(f"Tool result from {tool_name}: {tool_result}")
            # å¯¹äºsearch_similar_memorieså·¥å…·ï¼Œç›´æ¥æ˜¾ç¤ºç»“æœ
            if tool_name == "search_similar_memories":
                # ç›´æ¥å°†ç»“æœæ·»åŠ åˆ°å“åº”ä¸­ï¼Œè®©AIåŸºäºè¿™äº›ä¿¡æ¯ç”Ÿæˆå›å¤
                # ä½†æˆ‘ä»¬ä¸ç›´æ¥æ˜¾ç¤ºç»™ç”¨æˆ·ï¼Œè€Œæ˜¯è®©AIåŸºäºè¿™äº›ä¿¡æ¯ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
                # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œç¡®ä¿AIèƒ½çœ‹åˆ°
                if hasattr(output, 'agent') and hasattr(output.agent, 'conversation_history'):
                    output.agent.conversation_history.append({
                        "role": "system",
                        "content": f"å·¥å…· {tool_name} çš„æœç´¢ç»“æœ:\n{tool_result}"
                    })
            # å¯¹äºå…¶ä»–å·¥å…·ï¼Œä¸ç›´æ¥æ˜¾ç¤ºå·¥å…·è°ƒç”¨ç»“æœï¼Œè®©AIæ¥è§£é‡Šç»“æœ
            # å…¶ä»–å·¥å…·çš„ç»“æœå°†è¢«æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œä¾›AIå‚è€ƒ

        # å¤„ç†å¸¸è§„è¾“å‡º
        if isinstance(output, SentenceOutput):
            response = await handle_sentence_output(
                output,
                live2d_model,
                tts_engine,
                websocket_send,
                tts_manager,
                translate_engine,
                client_uid,
                tts_priority,
            )
            full_response += response
        elif isinstance(output, AudioOutput):
            response = await handle_audio_output(output, websocket_send)
            full_response += response
        else:
            logger.warning(f"Unknown output type: {type(output)}")
    except Exception as e:
        logger.error(f"Error processing agent output: {e}")
        await websocket_send(
            json.dumps(
                {"type": "error", "message": f"Error processing response: {str(e)}"}
            )
        )

    return full_response


async def handle_sentence_output(
        output: SentenceOutput,
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
        tts_manager: TTSTaskManager,
        translate_engine: Optional[Any] = None,
        client_uid: str = None,
        tts_priority: TTSPriority = TTSPriority.NORMAL,
) -> str:
    """Handle sentence output type with optional translation support"""
    full_response = ""
    async for display_text, tts_text, actions in output:

        # ğŸ”§ å¤‡ç”¨è¡¨æƒ…æå–é€»è¾‘ - å¦‚æœActionsä¸ºç©ºï¼Œç›´æ¥æå–è¡¨æƒ…
        if not actions or not actions.to_dict():

            # ä»æ˜¾ç¤ºæ–‡æœ¬ä¸­æå–è¡¨æƒ…
            if display_text and display_text.text:
                extracted_expressions = live2d_model.extract_emotion(display_text.text)
                if extracted_expressions:
                    # ğŸš¨ é™åˆ¶è¡¨æƒ…æ•°é‡ï¼Œé¿å…ç³»ç»Ÿè¿‡è½½
                    if len(extracted_expressions) > 3:
                        extracted_expressions = extracted_expressions[:3]

                    # ğŸ¯ å»é‡å¤„ç†ï¼Œé¿å…é‡å¤è¡¨æƒ…
                    unique_expressions = []
                    seen = set()
                    for expr in extracted_expressions:
                        if expr not in seen:
                            unique_expressions.append(expr)
                            seen.add(expr)
                    extracted_expressions = unique_expressions

                    logger.debug(f"å¤‡ç”¨æå–æˆåŠŸè¡¨æƒ…: {extracted_expressions}")

                    # åˆ›å»ºæ–°çš„Actionså¯¹è±¡
                    from ..agent.output_types import Actions
                    if not actions:
                        actions = Actions()
                    actions.expressions = extracted_expressions
                    # ğŸ­ è®¾ç½®æ’­æ”¾æ¨¡å¼ä¸ºåºåˆ—æ’­æ”¾
                    actions.isPlaylist = True

        # ç¿»è¯‘å¤„ç†
        if translate_engine:
            if len(re.sub(r'[\s.,!?ï¼Œã€‚ï¼ï¼Ÿ\'"ã€ã€ï¼‰ã€‘\s]+', "", tts_text)):
                tts_text = translate_engine.translate(tts_text)

        full_response += display_text.text
        
        # ç›´æ¥ä½¿ç”¨å…¨å±€TTSç®¡ç†å™¨ï¼Œç®€åŒ–é€»è¾‘
        logger.info(f"ğŸµ å‡†å¤‡è°ƒç”¨global_tts_manager.speakï¼Œæ–‡æœ¬: {tts_text[:100]}...")
        task_id = await global_tts_manager.speak(
            tts_text=tts_text,
            display_text=display_text,
            actions=actions,
            live2d_model=live2d_model,
            tts_engine=tts_engine,
            websocket_send=websocket_send,
            priority=tts_priority,
            client_uid=client_uid,
            enable_sentence_split=True,  # é»˜è®¤å¯ç”¨æ–­å¥åŠŸèƒ½
        )
        logger.info(f"ğŸµ global_tts_manager.speak è°ƒç”¨å®Œæˆï¼Œä»»åŠ¡ID: {task_id}")
    return full_response


async def handle_audio_output(
        output: AudioOutput,
        websocket_send: WebSocketSend,
) -> str:
    """Process and send AudioOutput directly to the client"""
    full_response = ""
    async for audio_path, display_text, transcript, actions in output:
        full_response += transcript
        audio_payload = prepare_audio_payload(
            audio_path=audio_path,
            display_text=display_text,
            actions=actions.to_dict() if actions else None,
        )
        await websocket_send(json.dumps(audio_payload))
    return full_response


async def send_conversation_start_signals(websocket_send: WebSocketSend) -> None:
    """Send initial conversation signals"""
    await websocket_send(
        json.dumps(
            {
                "type": "control",
                "text": "conversation-chain-start",
            }
        )
    )
    await websocket_send(json.dumps({"type": "full-text", "text": "Thinking..."}))


async def process_user_input(
        user_input: Union[str, np.ndarray],
        asr_engine: ASRInterface,
        websocket_send: WebSocketSend,
) -> str:
    """Process user input, converting audio to text if needed"""
    if isinstance(user_input, np.ndarray):
        logger.info("Transcribing audio input...")
        input_text = await asr_engine.async_transcribe_np(user_input)
        await websocket_send(
            json.dumps({"type": "user-input-transcription", "text": input_text})
        )
        return input_text
    return user_input


async def finalize_conversation_turn(
        tts_manager: TTSTaskManager,
        websocket_send: WebSocketSend,
        client_uid: str,
        context: ServiceContext = None
) -> None:
    """Finalize a conversation turn

    Args:
        tts_manager: TTSTaskManager instance
        websocket_send: WebSocket send function
        client_uid: Client unique identifier
        context: Optional service context for sending affinity updates
    """
    # ç­‰å¾…æ‰€æœ‰TTSä»»åŠ¡å®Œæˆåå†å‘é€ç»“æŸä¿¡å·
    logger.info("ğŸ¯ finalize_conversation_turn: å¼€å§‹ç­‰å¾…TTSä»»åŠ¡å®Œæˆ...")
    logger.info(f"ğŸ“Š TTSç®¡ç†å™¨ç±»å‹: {type(tts_manager).__name__}")

    tts_completed = await tts_manager.wait_for_all_tasks_complete(timeout=8.0)
    if not tts_completed:
        logger.warning("â° TTSä»»åŠ¡ç­‰å¾…è¶…æ—¶æˆ–å¤±è´¥ï¼Œå»¶è¿Ÿå‘é€ç»“æŸä¿¡å·")
        # å³ä½¿è¶…æ—¶ï¼Œä¹Ÿç»™ä¸€ç‚¹é¢å¤–æ—¶é—´è®©éŸ³é¢‘æ’­æ”¾
        await asyncio.sleep(2.0)
    else:
        logger.info("âœ… TTSä»»åŠ¡å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€ç»“æŸä¿¡å·")

    # åˆ›å»ºå¹¶è¡Œä»»åŠ¡åˆ—è¡¨
    tasks = []

    # æ·»åŠ å‘é€ç»“æŸä¿¡å·ä»»åŠ¡
    tasks.append(send_conversation_end_signal(websocket_send))

    # å¦‚æœæœ‰æƒ…æ„Ÿç³»ç»Ÿï¼Œæ·»åŠ å‘é€æƒ…æ„Ÿæ›´æ–°ä»»åŠ¡
    if context and context.emotion_manager:
        async def send_affinity_update():
            try:
                character_id = context.character_config.conf_uid
                
                # è·å–ç”¨æˆ·ID - ä¼˜å…ˆä»WebSocketç¼“å­˜ï¼Œå›é€€åˆ°Context Variableï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
                user_id = None
                try:
                    from ..bff_integration.auth.websocket_user_cache import get_user_id_for_websocket_client
                    user_id = get_user_id_for_websocket_client(client_uid)
                except Exception:
                    pass
                
                if not user_id:
                    try:
                        from ..bff_integration.auth.user_context import UserContextManager
                        user_id = UserContextManager.get_current_user_id()
                    except Exception:
                        pass
                        
                if not user_id:
                    user_id = "default_user"
                
                affinity = context.emotion_manager.get_affinity(character_id, user_id)
                level = context.emotion_manager.get_affinity_level(affinity)

                await websocket_send(json.dumps({
                    "type": "affinity-update",
                    "affinity": affinity,
                    "level": level
                }))
            except Exception as e:
                logger.error(f"å‘é€æƒ…æ„Ÿæ›´æ–°é”™è¯¯: {e}")
        
        tasks.append(send_affinity_update())
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œè®¾ç½®è¶…æ—¶é¿å…å¡æ­»
    if tasks:
        try:
            # è®¾ç½®1ç§’è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
            await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True), 
                timeout=1.0
            )
        except asyncio.TimeoutError:
            logger.warning("ç»“æŸå¯¹è¯ä»»åŠ¡è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ")
        except Exception as e:
            logger.error(f"ç»“æŸå¯¹è¯è½®æ¬¡é”™è¯¯: {e}")


async def send_conversation_end_signal(
        websocket_send: WebSocketSend,
        broadcast_ctx: Optional[BroadcastContext] = None,
        session_emoji: str = "ğŸ˜Š",
) -> None:
    """Send conversation chain end signal"""
    chain_end_msg = {
        "type": "control",
        "text": "conversation-chain-end",
    }

    await websocket_send(json.dumps(chain_end_msg))

    if broadcast_ctx and broadcast_ctx.broadcast_func and broadcast_ctx.group_members:
        await broadcast_ctx.broadcast_func(
            broadcast_ctx.group_members,
            chain_end_msg,
        )

    logger.info(f"ğŸ˜ğŸ‘âœ… Conversation Chain {session_emoji} completed!")


def cleanup_conversation(tts_manager: TTSTaskManager, session_emoji: str) -> None:
    """Clean up conversation resources"""
    # åªæœ‰ä¼ ç»Ÿçš„TTSTaskManageræ‰éœ€è¦æ¸…ç†ï¼Œå…¨å±€ç®¡ç†å™¨ä¸åº”è¢«å•ä¸ªå¯¹è¯æ¸…ç†
    if hasattr(tts_manager, '__class__') and tts_manager.__class__.__name__ == 'TTSTaskManager':
        tts_manager.clear()
        logger.debug(f"ğŸ§¹ Clearing up local TTS manager for conversation {session_emoji}.")
    else:
        # å…¨å±€TTSç®¡ç†å™¨ä¸éœ€è¦æ¸…ç†ï¼Œå› ä¸ºå¯èƒ½æœ‰å…¶ä»–å¯¹è¯åœ¨ä½¿ç”¨
        logger.debug(f"ğŸ§¹ Conversation {session_emoji} ended, but keeping global TTS manager active.")


EMOJI_LIST = [
    "ğŸ¶",
    "ğŸ±",
    "ğŸ­",
    "ğŸ¹",
    "ğŸ°",
    "ğŸ¦Š",
    "ğŸ»",
    "ğŸ¼",
    "ğŸ¨",
    "ğŸ¯",
    "ğŸ¦",
    "ğŸ®",
    "ğŸ·",
    "ğŸ¸",
    "ğŸµ",
    "ğŸ”",
    "ğŸ§",
    "ğŸ¦",
    "ğŸ¤",
    "ğŸ£",
    "ğŸ¥",
    "ğŸ¦†",
    "ğŸ¦…",
    "ğŸ¦‰",
    "ğŸ¦‡",
    "ğŸº",
    "ğŸ—",
    "ğŸ´",
    "ğŸ¦„",
    "ğŸ",
    "ğŸŒµ",
    "ğŸ„",
    "ğŸŒ²",
    "ğŸŒ³",
    "ğŸŒ´",
    "ğŸŒ±",
    "ğŸŒ¿",
    "â˜˜ï¸",
    "ğŸ€",
    "ğŸ‚",
    "ğŸ",
    "ğŸ„",
    "ğŸŒ¾",
    "ğŸ’",
    "ğŸŒ¹",
    "ğŸŒ¸",
    "ğŸŒ›",
    "ğŸŒ",
    "â­ï¸",
    "ğŸ”¥",
    "ğŸŒˆ",
    "ğŸŒ©",
    "â›„ï¸",
    "ğŸƒ",
    "ğŸ„",
    "ğŸ‰",
    "ğŸ",
    "ğŸ—",
    "ğŸ€„ï¸",
    "ğŸ­",
    "ğŸ¨",
    "ğŸ§µ",
    "ğŸª¡",
    "ğŸ§¶",
    "ğŸ¥½",
    "ğŸ¥¼",
    "ğŸ¦º",
    "ğŸ‘”",
    "ğŸ‘•",
    "ğŸ‘œ",
    "ğŸ‘‘",
]
