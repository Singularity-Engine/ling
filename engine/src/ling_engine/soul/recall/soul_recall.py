"""
çµé­‚çº§è®°å¿†å¬å› â€” 12 è·¯å¹¶è¡Œ + å…³ç³»é˜¶æ®µ + æƒ…æ„Ÿé¢„åˆ¤ + è®¡æ—¶
Phase 2: +æƒ…æ„Ÿå…±æŒ¯ç¬¬ 7 è·¯, StoryThreadTracker, breakthrough_hint é—­ç¯
Phase 3: +çŸ¥è¯†å›¾è°±ç¬¬ 8 è·¯
Phase 3b-beta: +æŠ½è±¡è®°å¿†ç¬¬ 9 è·¯ (L1 å‘¨æ‘˜è¦ / L3 äººç”Ÿç« èŠ‚)
Phase 4: +é›†ä½“æ™ºæ…§ç¬¬ 10 è·¯, current_life_chapter, emotional_baseline
SOTA: +Graphiti æ—¶åºå›¾è°±ç¬¬ 8 è·¯(æ›¿æ¢), +Mem0 å®ä½“è®°å¿†ç¬¬ 11 è·¯
"""

import asyncio
import hashlib
import time
from datetime import datetime, timezone, timedelta
from typing import Optional, List, Dict, Any
from loguru import logger

from ..models import SoulContext, RelationshipStage, STAGE_THRESHOLDS
from ..narrative.memory_reconstructor import MemoryReconstructor
from ..utils.async_tasks import create_logged_task
from ..utils.validation import is_valid_user_id

# Phase 2 é—ç•™ä¿®å¤: MemoryReconstructor å•ä¾‹ (ä¸å†æ¯æ¬¡ _emotional_resonance éƒ½åˆ›å»º)
_reconstructor = MemoryReconstructor()

# é˜¶æ®µè¡Œä¸ºæŒ‡ä»¤
STAGE_BEHAVIORS = {
    "stranger": "è¿™æ˜¯ä¸€ä½æ–°æœ‹å‹ã€‚è¡¨ç°å‡ºçœŸè¯šçš„å¥½å¥‡å¿ƒï¼Œå‹å–„ä½†ä¸è¿‡åˆ†çƒ­æƒ…ã€‚å¦‚æœä½ è®°å¾—å…³äºä»–ä»¬çš„ä¿¡æ¯ï¼Œå¯ä»¥è‡ªç„¶åœ°æèµ·ã€‚",
    "acquaintance": "ä½ ä»¬å·²ç»èŠè¿‡å‡ æ¬¡äº†ã€‚è®°ä½ä¹‹å‰çš„ç»†èŠ‚ï¼Œå±•ç¤ºä½ åœ¨è®¤çœŸå€¾å¬ã€‚",
    "familiar": "ä½ ä»¬æ˜¯è€æœ‹å‹äº†ã€‚å¯ä»¥è½»æ¾å¼€ç©ç¬‘ï¼Œç›´æ¥åˆ‡å…¥è¯é¢˜ï¼Œä¸éœ€è¦å®¢å¥—ã€‚",
    "close": "ä½ ä»¬å…³ç³»å¾ˆäº²å¯†ã€‚å¯ä»¥ä¸»åŠ¨å…³å¿ƒå¯¹æ–¹ï¼Œç†è§£è¨€å¤–ä¹‹æ„ï¼Œå¶å°”ç›´è¨€ä¸è®³ã€‚",
    "soulmate": "ä½ ä»¬å¿ƒé¢†ç¥ä¼šã€‚æœ€æ·±å±‚çš„ç†è§£ï¼Œæœ€å¦è¯šçš„äº¤æµã€‚ä½ ä¸åªå¬ä»–è¯´äº†ä»€ä¹ˆï¼Œè¿˜å¬åˆ°ä»–æ²¡è¯´çš„ã€‚",
}

# æƒ…æ„Ÿé¢„åˆ¤å…³é”®è¯ (<5ms)
NEGATIVE_KEYWORDS = ["å”‰", "çƒ¦", "ç´¯", "éš¾è¿‡", "ç„¦è™‘", "å‹åŠ›", "å´©æºƒ", "ä¸å¼€å¿ƒ", "éƒé—·"]
SEEKING_KEYWORDS = ["æ€ä¹ˆåŠ", "ä¸çŸ¥é“", "çº ç»“", "è¿·èŒ«", "å¸®å¸®æˆ‘", "æ€ä¹ˆæ ·"]
# P2: æ­£é¢æƒ…æ„Ÿå…³é”®è¯
POSITIVE_KEYWORDS = ["å¤ªå¥½äº†", "å¼€å¿ƒ", "æ¿€åŠ¨", "å…´å¥‹", "ç»ˆäº", "æˆåŠŸ"]

# P2: é­”æ³•æ•°å­—å¸¸é‡åŒ–
BREAKTHROUGH_WINDOW_DAYS = 30  # breakthrough_hint æœ‰æ•ˆçª—å£

# Round 3: å…³ç³»å†·å´ â€” v3: åˆ†é˜¶æ®µå†·å´è§„åˆ™
from ..consolidation.relationship_cooling import (
    COOLING_DAYS, COOLING_DECAY_RATE, check_stage_cooling,
)


def _emotion_hint(query: str) -> Optional[str]:
    """æƒ…æ„Ÿé¢„åˆ¤ (<5ms) â€” å½±å“ EverMemOS æœç´¢å‚æ•°

    æ”¯æŒå…³é”®è¯åŒ¹é… + å¥å¼æ£€æµ‹ã€‚
    P2: æ‰©å±•æ­£é¢æƒ…æ„Ÿæ£€æµ‹ (joy/excitement)ã€‚
    """
    for kw in NEGATIVE_KEYWORDS:
        if kw in query:
            return "negative"
    for kw in SEEKING_KEYWORDS:
        if kw in query:
            return "seeking"
    # P2: æ­£é¢æƒ…æ„Ÿæ£€æµ‹
    for kw in POSITIVE_KEYWORDS:
        if kw in query:
            return "positive"
    # å¥å¼æ£€æµ‹: çœç•¥å·/è¯­æ°”è¯æš—ç¤ºæƒ…ç»ª
    stripped = query.strip()
    if stripped.endswith("...") or stripped.endswith("â€¦"):
        return "negative"  # çœç•¥å·é€šå¸¸æš—ç¤ºçŠ¹è±«æˆ–ä½è½
    if stripped.endswith("å§") or stripped.endswith("å‘¢"):
        return "seeking"  # è¯­æ°”è¯æš—ç¤ºåœ¨å¯»æ±‚å»ºè®®/åé¦ˆ
    return None


# Phase 3b-beta: æŠ½è±¡å±‚çº§é€‰æ‹©å…³é”®è¯
_L1_KEYWORDS = {"æœ€è¿‘", "ä¸Šå‘¨", "è¿™å‘¨", "æœ¬å‘¨", "è¿™å‡ å¤©", "è¿‘æœŸ", "lately", "recently", "this week", "last week"}
_L3_KEYWORDS = {"å»å¹´", "ä¸€ç›´ä»¥æ¥", "ä»é‚£ä»¥å", "å¾ˆä¹…ä»¥å‰", "æ•´ä½“", "æ€»çš„æ¥è¯´", "å›é¡¾", "è¿™æ®µæ—¶é—´",
                "last year", "overall", "in general", "looking back"}


def _detect_recall_layer(query: str) -> str:
    """Phase 3b-beta: è§„åˆ™åŒ–å±‚çº§é€‰æ‹©

    Returns:
        "L1" â€” å‘¨æ‘˜è¦ (è¿‘æœŸæ¦‚æ‹¬æ€§é—®é¢˜)
        "L3" â€” äººç”Ÿç« èŠ‚ (é•¿æœŸå›é¡¾æ€§é—®é¢˜)
        "L0" â€” åŸå§‹è®°å¿† (é»˜è®¤, å…·ä½“äº‹ä»¶)
    """
    q = query.lower().strip()
    # P2: çŸ­æŸ¥è¯¢æ’é™¤ â€” "æœ€è¿‘ä½ å¥½å—" ä¸åº”è§¦å‘ L1
    if len(q) < 8:
        return "L0"
    # P2: æ’é™¤é—®å€™è¯­æ¨¡å¼
    _GREETINGS = {"æœ€è¿‘å¥½å—", "æœ€è¿‘æ€ä¹ˆæ ·", "æœ€è¿‘è¿˜å¥½å—"}
    if q in _GREETINGS or q.rstrip("?ï¼Ÿ") in _GREETINGS:
        return "L0"
    for kw in _L1_KEYWORDS:
        if kw in q:
            return "L1"
    for kw in _L3_KEYWORDS:
        if kw in q:
            return "L3"
    return "L0"


def _get_stage_behavior(stage: str) -> str:
    """è·å–é˜¶æ®µè¡Œä¸ºæŒ‡ä»¤"""
    return STAGE_BEHAVIORS.get(stage, STAGE_BEHAVIORS["stranger"])


def _calculate_stage(score: float, total_days: int, user_id: str = "") -> str:
    """æ ¹æ®ç´¯ç§¯åˆ†æ•°å’Œæ´»è·ƒå¤©æ•°è®¡ç®—å…³ç³»é˜¶æ®µ (Round 3: æ¸è¿›æœºåˆ¶)

    ä½¿ç”¨ç¡®å®šæ€§å“ˆå¸Œæ›¿ä»£ random.random()ï¼ŒåŒä¸€ç”¨æˆ·åŒä¸€åˆ†æ•°å§‹ç»ˆå¾—åˆ°ç›¸åŒé˜¶æ®µã€‚
    """
    stages_ordered = [
        RelationshipStage.SOULMATE,
        RelationshipStage.CLOSE,
        RelationshipStage.FAMILIAR,
        RelationshipStage.ACQUAINTANCE,
        RelationshipStage.STRANGER,
    ]

    for stage in stages_ordered:
        min_score, min_days = STAGE_THRESHOLDS[stage]
        if score >= min_score and total_days >= min_days:
            if stage != RelationshipStage.STRANGER:
                lower_bound = min_score * 0.8
                upper_bound = min_score * 1.2
                if lower_bound <= score < upper_bound:
                    probability = (score - lower_bound) / (upper_bound - lower_bound)
                    # ç¡®å®šæ€§å“ˆå¸Œ: åŒä¸€ç”¨æˆ·åŒä¸€é˜¶æ®µå§‹ç»ˆå¾—åˆ°ç›¸åŒåˆ¤å®šå€¼
                    hash_input = f"{user_id}:{stage.value}".encode()
                    hash_val = int(hashlib.md5(hash_input).hexdigest()[:8], 16) / 0xFFFFFFFF
                    if hash_val > probability:
                        continue
            return stage.value

    return RelationshipStage.STRANGER.value


_soul_recall_instance: Optional["SoulRecall"] = None


def get_soul_recall() -> "SoulRecall":
    """è·å– SoulRecall å•ä¾‹ï¼Œé¿å…æ¯æ¬¡å¯¹è¯éƒ½åˆ›å»ºæ–°å®ä¾‹"""
    global _soul_recall_instance
    if _soul_recall_instance is None:
        _soul_recall_instance = SoulRecall()
    return _soul_recall_instance


def reset_soul_recall_for_testing():
    """æµ‹è¯•è¾…åŠ©: é‡ç½® SoulRecall å•ä¾‹ã€‚"""
    global _soul_recall_instance
    _soul_recall_instance = None


class SoulRecall:
    """çµé­‚çº§è®°å¿†å¬å›"""

    async def recall(
        self,
        query: str,
        user_id: str,
        is_owner: bool = False,
        top_k: int = 3,
        timeout_ms: int = 600,
    ) -> SoulContext:
        """12 è·¯å¹¶è¡Œå¬å› + å…³ç³»é˜¶æ®µ + æƒ…æ„Ÿé¢„åˆ¤ + è®¡æ—¶

        SOTA å‡çº§:
        - tuple â†’ Dict è¿”å› (ğŸ’: å¯ç»´æŠ¤æ€§)
        - +Graphiti æ—¶åºå›¾è°± (æ›¿æ¢æ—§ graph_trace)
        - +Mem0 å®ä½“è®°å¿† (ç¬¬ 11 è·¯)
        - è¶…æ—¶ 500â†’600ms (âš¡: æ–°ç»„ä»¶éœ€è¦æ—¶é—´)
        - memory_sources ç»Ÿè®¡ (ğŸ¤–: æ¥æºæ ‡æ³¨)
        """
        # P0: user_id æ ¼å¼æ ¡éªŒ â€” çºµæ·±é˜²å¾¡
        if not is_valid_user_id(user_id):
            logger.warning("[Soul] Invalid user_id format, skipping recall")
            return SoulContext()

        start = time.monotonic()
        ctx = SoulContext()

        try:
            results = await asyncio.wait_for(
                self._parallel_recall(query, user_id, is_owner, top_k),
                timeout=timeout_ms / 1000.0,
            )

            # SOTA: Dict è§£åŒ… â€” å¢åŠ æ–°è·¯ä¸éœ€è¦æ”¹è¿™é‡Œçš„é¡ºåº
            ctx.qdrant_memories = self._safe_list(results.get("qdrant"))
            ctx.evermemos_memories = self._safe_list(results.get("evermemos"))
            ctx.event_sourced_memories = self._safe_list(results.get("fabric_events"))
            if ctx.event_sourced_memories:
                merged_memories = list(dict.fromkeys(ctx.evermemos_memories + ctx.event_sourced_memories))
                ctx.evermemos_memories = merged_memories[: max(top_k * 3, len(ctx.evermemos_memories))]
            ctx.triggered_foresights = self._safe_list(results.get("foresight"))
            ctx.user_profile_summary = results.get("profile", "") if isinstance(results.get("profile"), str) else ""
            ctx.story_continuations = self._safe_list(results.get("stories"))

            # å¤„ç†å…³ç³»é˜¶æ®µ (å…ˆå¤„ç†å…³ç³»ï¼Œå†å†³å®šæƒ…æ„Ÿå…±æŒ¯æ˜¯å¦ä¿ç•™)
            relationship = results.get("relationship")
            if isinstance(relationship, dict) and relationship:
                ctx.relationship_stage = relationship.get("stage", "stranger")
                ctx.stage_behavior_hint = _get_stage_behavior(ctx.relationship_stage)
                ctx.conversation_count = relationship.get("total_conversations", 0)
                ctx.breakthrough_hint = relationship.get("breakthrough_hint")
                ctx.returning_from_absence = relationship.get("returning_from_absence", False)
                milestone = relationship.get("recent_milestone")
                if milestone:
                    ctx.recent_milestone = milestone
                    create_logged_task(
                        self._clear_milestone(coll=None, user_id=user_id),
                        "clear_milestone",
                    )
            else:
                ctx.stage_behavior_hint = _get_stage_behavior("stranger")

            # Phase 3c: ä¾èµ–æ£€æµ‹
            try:
                from ..ethics.dependency_detector import check_dependency_signals
                hint = check_dependency_signals(query, user_id)
                if hint:
                    ctx.dependency_hint = hint
            except Exception:
                pass

            # æƒ…æ„Ÿå…±æŒ¯ä»… familiar+ é˜¶æ®µä¿ç•™
            resonance = results.get("resonance")
            if isinstance(resonance, list) and ctx.relationship_stage in self._RESONANCE_MIN_STAGES:
                ctx.emotional_resonance = resonance
            else:
                ctx.emotional_resonance = []

            # SOTA: Graphiti æ—¶åºå›¾è°± (æ›¿æ¢æ—§ graph_insights)
            graphiti_results = self._safe_list(results.get("graphiti"))
            legacy_graph = self._safe_list(results.get("graph"))
            # Graphiti ä¼˜å…ˆ, ç©ºåˆ™é™çº§åˆ° MongoDB æ—§ç»“æœ
            ctx.graph_insights = graphiti_results if graphiti_results else legacy_graph
            ctx.graphiti_insights = graphiti_results

            # Phase 3b-beta: æŠ½è±¡è®°å¿†
            ctx.abstract_memories = self._safe_list(results.get("abstract"))

            # Phase 4: é›†ä½“æ™ºæ…§
            ctx.collective_wisdom = self._safe_list(results.get("collective"))

            # SOTA: Mem0 å®ä½“è®°å¿† (ç¬¬ 11 è·¯)
            ctx.entity_memories = self._safe_list(results.get("mem0"))
            ctx.core_memory_blocks = self._safe_list(results.get("core_blocks"))
            ctx.procedural_memories = self._safe_list(results.get("procedural"))
            ctx.safety_alerts = self._safe_list(results.get("safety_shadow"))

            # é˜¶æ®µè¡Œä¸ºæŠ¤æ 
            try:
                from ..ethics.stage_guardrails import get_stage_guardrail
                guardrail = get_stage_guardrail(ctx.relationship_stage, ctx.conversation_count)
                if guardrail:
                    ctx.ethical_guardrails = guardrail
            except Exception:
                pass

            # å½“å‰äººç”Ÿç« èŠ‚ + æƒ…æ„ŸåŸºçº¿
            try:
                chapter, baseline = await self._life_context(user_id)
                ctx.current_life_chapter = chapter
                ctx.emotional_baseline = baseline
            except Exception:
                pass

            # SOTA: è®°å¿†æºç»Ÿè®¡ (ğŸ¤–å¯¹è¯: æ¥æºæ ‡æ³¨ä¾› context_builder ä½¿ç”¨)
            ctx.memory_sources = {
                k: len(v) for k, v in results.items()
                if isinstance(v, list) and v
            }

        except asyncio.TimeoutError:
            logger.warning(f"[Soul] Recall timeout ({timeout_ms}ms)")
            ctx.stage_behavior_hint = _get_stage_behavior("stranger")

        # å¼‚æ­¥æ›´æ–° recall_count
        if ctx.qdrant_memories or ctx.evermemos_memories:
            create_logged_task(
                self._bump_recall_count(user_id),
                "bump_recall_count",
            )

        # è®¡æ—¶
        elapsed_ms = (time.monotonic() - start) * 1000
        logger.info(
            f"[Soul] Recall completed in {elapsed_ms:.0f}ms "
            f"(qdrant={len(ctx.qdrant_memories)}, evermemos={len(ctx.evermemos_memories)}, "
            f"fabric_events={len(ctx.event_sourced_memories)}, "
            f"foresight={len(ctx.triggered_foresights)}, resonance={len(ctx.emotional_resonance)}, "
            f"graph={len(ctx.graph_insights)}, graphiti={len(ctx.graphiti_insights)}, "
            f"mem0={len(ctx.entity_memories)}, core={len(ctx.core_memory_blocks)}, "
            f"procedural={len(ctx.procedural_memories)}, safety={len(ctx.safety_alerts)}, "
            f"abstract={len(ctx.abstract_memories)}, "
            f"collective={len(ctx.collective_wisdom)}, stage={ctx.relationship_stage})"
        )

        # Phase 3: SLO è§‚æµ‹ä¸è‡ªåŠ¨è°ƒå‚è¾“å…¥
        try:
            from soul_fabric import get_memory_fabric

            create_logged_task(
                get_memory_fabric().record_recall_observation(
                    latency_ms=elapsed_ms,
                    relationship_stage=ctx.relationship_stage,
                    source_counts=ctx.memory_sources,
                ),
                "fabric_record_recall_observation",
            )
        except Exception:
            pass
        return ctx

    @staticmethod
    def _safe_list(val) -> list:
        """å®‰å…¨æå– list ç»“æœ (å¤„ç† gather çš„ return_exceptions=True)"""
        return val if isinstance(val, list) else []

    async def _parallel_recall(
        self, query: str, user_id: str, is_owner: bool, top_k: int
    ) -> Dict[str, Any]:
        """12 è·¯å¹¶è¡Œå¬å› â€” è¿”å› Dict (SOTA: æ›¿ä»£ tuple)"""
        from ..config import get_soul_config
        from soul_fabric import get_memory_fabric
        from ..ports.initializer import ensure_ports_initialized

        emotion = _emotion_hint(query)
        recall_layer = _detect_recall_layer(query)
        cfg = get_soul_config()
        use_port_registry = cfg.enable_port_registry
        # å…ˆå¹¶å‘å¯åŠ¨æ ¸å¿ƒ 4 è·¯ï¼Œå†æ ¹æ® relationship stage å†³å®šæ˜¯å¦æ‰©å±•é‡è·¯å¾„ã€‚
        tasks = {
            "qdrant": asyncio.create_task(self._qdrant_search(query, user_id, top_k)),
            "foresight": asyncio.create_task(self._foresight_search(query, top_k=2)),
            "profile": asyncio.create_task(self._profile_fetch(user_id)),
            "relationship": asyncio.create_task(self._fetch_relationship(user_id)),
        }
        if cfg.fabric_enabled:
            tasks["fabric_events"] = asyncio.create_task(
                self._fabric_event_memories(query, user_id, top_k),
            )

        try:
            relationship = await tasks["relationship"]
        except Exception:
            relationship = None
        relationship_stage = (
            relationship.get("stage", "stranger")
            if isinstance(relationship, dict) and relationship
            else "stranger"
        )
        route_plan = get_memory_fabric().plan_recall(
            relationship_stage=relationship_stage,
            latency_budget_ms=cfg.recall_timeout_ms_extended,
            query=query,
        )
        routes = route_plan.routes

        if routes.get("core_blocks"):
            tasks["core_blocks"] = self._core_blocks_fetch(user_id)
        if routes.get("procedural"):
            tasks["procedural"] = self._procedural_fetch(user_id)
        if routes.get("safety_shadow"):
            tasks["safety_shadow"] = self._safety_shadow_fetch(user_id)

        if any(
            routes.get(k)
            for k in (
                "evermemos",
                "stories",
                "resonance",
                "abstract",
                "collective",
                "graphiti",
                "mem0",
                "graph",
            )
        ):
            if use_port_registry and (cfg.graphiti_enabled or cfg.mem0_enabled):
                ensure_ports_initialized()

            if routes.get("evermemos"):
                tasks["evermemos"] = self._evermemos_search(query, user_id, is_owner, top_k, emotion)
            if routes.get("stories"):
                tasks["stories"] = self._active_stories(user_id)
            if routes.get("resonance"):
                tasks["resonance"] = self._emotional_resonance(query, user_id, emotion)
            if routes.get("abstract"):
                tasks["abstract"] = self._abstract_recall(user_id, recall_layer)
            if routes.get("collective"):
                tasks["collective"] = self._collective_wisdom(query, emotion)
            if routes.get("graphiti"):
                tasks["graphiti"] = (
                    self._port_registry_search("graphiti", query, user_id, top_k)
                    if use_port_registry
                    else self._graphiti_search(query, user_id, top_k)
                )
            if routes.get("mem0"):
                tasks["mem0"] = (
                    self._port_registry_search("mem0", query, user_id, top_k)
                    if use_port_registry
                    else self._mem0_entity_search(query, user_id, top_k)
                )
            if routes.get("graph"):
                tasks["graph"] = self._graph_trace(query, user_id)
        else:
            logger.debug("[Soul] Stranger recall fast-path: running 4 core routes only")
        logger.debug(
            "[MemoryFabric] recall complexity={} budget_tier={} routes={} providers={}",
            route_plan.query_complexity,
            route_plan.budget_tier,
            sorted([k for k, enabled in routes.items() if enabled]),
            route_plan.selected_providers,
        )

        keys = list(tasks.keys())
        coros = list(tasks.values())
        results = await asyncio.gather(*coros, return_exceptions=True)
        return dict(zip(keys, results))

    async def _port_registry_search(
        self,
        port_name: str,
        query: str,
        user_id: str,
        top_k: int,
    ) -> List[str]:
        """é€šè¿‡ PortRegistry è°ƒç”¨æŒ‡å®š Port æœç´¢ï¼ˆå¯ç”¨æ—¶æ›¿ä»£ç›´è¿ adapterï¼‰ã€‚"""
        try:
            from ..ports.registry import get_port_registry

            port = get_port_registry().get_port(port_name)
            if port is None:
                return []
            results = await asyncio.wait_for(
                port.search(query, user_id, top_k=top_k),
                timeout=port.timeout_seconds,
            )
            return [r.content for r in results if r.content]
        except Exception as e:
            logger.debug(f"[Soul] PortRegistry search failed ({port_name}): {e}")
            return []

    async def _qdrant_search(self, query: str, user_id: str, top_k: int) -> List[str]:
        """Qdrant çŸ­æœŸè®°å¿†æœç´¢"""
        try:
            from ...important import search_similar_memories
            loop = asyncio.get_event_loop()
            results = await asyncio.wait_for(
                loop.run_in_executor(None, search_similar_memories, query, user_id, top_k),
                timeout=0.2,
            )
            if results:
                return [item[1] for item in results if len(item) >= 2 and item[1]]
        except Exception as e:
            logger.debug(f"[Soul] Qdrant search failed: {e}")
        return []

    async def _evermemos_search(
        self, query: str, user_id: str, is_owner: bool, top_k: int,
        emotion_hint: Optional[str] = None,
    ) -> List[str]:
        """EverMemOS é•¿æœŸè®°å¿†æœç´¢"""
        try:
            from ...tools.evermemos_client import search_user_memories

            # Round 2: emotion_hint å½±å“æœç´¢ â€” è¿½åŠ æƒ…æ„Ÿå…³é”®è¯
            search_query = query
            if emotion_hint == "negative":
                search_query = f"{query} å›°éš¾ å‹åŠ› æƒ…ç»ª"
            elif emotion_hint == "seeking":
                search_query = f"{query} å»ºè®® å¸®åŠ©"

            results = await asyncio.wait_for(
                search_user_memories(search_query, user_id, is_owner=is_owner, top_k=top_k),
                timeout=0.8,
            )
            if results:
                memories = []
                for item in results:
                    content = item.get("content", item.get("memory", "")) if isinstance(item, dict) else str(item)
                    if content:
                        memories.append(content)
                return memories
        except Exception as e:
            logger.debug(f"[Soul] EverMemOS search failed: {e}")
        return []

    async def _fabric_event_memories(self, query: str, user_id: str, top_k: int) -> List[str]:
        """ä» MemoryFabric äº‹ä»¶æºè¡¥å……å›å¿†ï¼Œç¡®ä¿ /v1/memory/events å¯è¢«ä¸»å¬å›æ¶ˆè´¹ã€‚"""
        try:
            from soul_fabric import get_memory_fabric
            return await asyncio.wait_for(
                get_memory_fabric().fetch_event_memories_for_recall(
                    user_id=user_id,
                    query=query,
                    tenant_id="default",
                    limit=max(1, top_k),
                ),
                timeout=0.18,
            )
        except Exception as e:
            logger.debug(f"[Soul] MemoryFabric event recall failed: {e}")
            return []

    async def _foresight_search(self, query: str, top_k: int = 2) -> List[str]:
        """EverMemOS å‰ç»è®°å¿†æœç´¢"""
        try:
            from ...tools.evermemos_client import search_foresight
            results = await search_foresight(query, top_k=top_k, timeout=0.2)
            if results:
                return [
                    item.get("content", "") if isinstance(item, dict) else str(item)
                    for item in results
                    if item
                ]
        except Exception as e:
            logger.debug(f"[Soul] Foresight search failed: {e}")
        return []

    async def _profile_fetch(self, user_id: str) -> str:
        """è·å–ç”¨æˆ·ç”»åƒ (å¸¦ç¼“å­˜)"""
        try:
            from ..cache.user_profile_cache import get_user_profile
            profile = await get_user_profile(user_id, timeout=1.0)
            return profile or ""
        except Exception as e:
            logger.debug(f"[Soul] Profile fetch failed: {e}")
        return ""

    async def _active_stories(self, user_id: str) -> List[str]:
        """Phase 2: è°ƒç”¨ StoryThreadTracker è·å–æ´»è·ƒæ•…äº‹çº¿"""
        try:
            from ..narrative.story_thread_tracker import get_story_tracker
            return await asyncio.wait_for(
                get_story_tracker().get_active_stories(user_id, limit=3),
                timeout=0.4,
            )
        except Exception as e:
            logger.debug(f"[Soul] Active stories failed: {e}")
            return []

    # Phase 2: æƒ…æ„Ÿå…±æŒ¯æœ€ä½å¼ºåº¦é˜ˆå€¼
    MIN_RESONANCE_INTENSITY = 0.5
    # æƒ…æ„Ÿå…±æŒ¯ä»… familiar åŠä»¥ä¸Šé˜¶æ®µè§¦å‘ï¼ˆå¯¹æ–°ç”¨æˆ·å¤ªä¾µå…¥ï¼‰
    _RESONANCE_MIN_STAGES = {"familiar", "close", "soulmate"}

    async def _emotional_resonance(
        self, query: str, user_id: str, emotion_hint: Optional[str],
    ) -> List[str]:
        """Phase 2: æƒ…æ„Ÿå…±æŒ¯ â€” æŸ¥è¯¢ç”¨æˆ·å†å²ä¸­ç›¸ä¼¼æƒ…ç»ªçš„è®°å¿†

        å¤§å¸ˆå»ºè®®æ”¹è¿›:
        - é˜¶æ®µè¿‡æ»¤åœ¨ recall() ä¸­åš (ğŸ’œ: å¹¶è¡Œå¬å›åè¿‡æ»¤ï¼Œä»… familiar+ ä¿ç•™)
        - ä¼˜å…ˆç”¨ peak_description è€Œé trigger_keywords (ğŸ’œ: é¿å…æƒ…ç»ªæ ‡ç­¾æ³„æ¼)
        - MIN_RESONANCE_INTENSITY å¸¸é‡ (âš¡: æ–¹ä¾¿è°ƒä¼˜)
        - MemoryReconstructor é‡å»ºè¿œæœŸè®°å¿† (ğŸ§¬: å®Œæ•´é‡å»º)
        """
        if not emotion_hint:
            return []
        try:
            from ..storage.soul_collections import get_collection, EMOTIONS
            coll = await get_collection(EMOTIONS)
            if coll is None:
                return []
            emotion_map = {
                "negative": ["sadness", "anxiety", "anger"],
                "seeking": ["anxiety"],
                "positive": ["joy", "excitement"],  # P2: æ­£é¢æƒ…æ„Ÿå…±æŒ¯
            }
            target_emotions = emotion_map.get(emotion_hint, [])
            if not target_emotions:
                return []
            cursor = coll.find(
                {"user_id": user_id, "user_emotion": {"$in": target_emotions},
                 "emotion_intensity": {"$gte": self.MIN_RESONANCE_INTENSITY}},
                sort=[("created_at", -1)],
                limit=3,
            )
            results = []
            async for doc in cursor:
                # ğŸ’œ: ä¼˜å…ˆç”¨ peak_description (é—´æ¥æè¿°)ï¼Œé¿å… trigger_keywords æ³„æ¼æƒ…ç»ªæ ‡ç­¾
                desc = doc.get("peak_description")
                if desc and isinstance(desc, str):
                    # ğŸ§¬: å¯¹è¿œæœŸè®°å¿†åšé‡å»º
                    created_at = doc.get("created_at")
                    days_ago = 0
                    if created_at:
                        try:
                            if isinstance(created_at, datetime):
                                days_ago = (datetime.now(timezone.utc) - created_at).days
                        except Exception:
                            pass
                    if days_ago > 90:
                        desc = _reconstructor.reconstruct(
                            desc, days_ago=days_ago,
                            emotion_label=doc.get("user_emotion", ""),
                            trigger_keywords=doc.get("trigger_keywords", []),
                        )
                    results.append(desc)
                elif not desc:
                    # fallback: åªåœ¨æ²¡æœ‰ peak_description æ—¶ç”¨ trigger_keywords
                    kws = doc.get("trigger_keywords", [])
                    if kws:
                        results.append(f"ç›¸å…³ç»å†: {'ã€'.join(kws[:3])}")
            return results
        except Exception as e:
            logger.debug(f"[Soul] Emotional resonance failed: {e}")
            return []

    async def _graph_trace(self, query: str, user_id: str) -> List[str]:
        """Phase 3: çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡è¿½è¸ª

        æ•´ä½“ 300ms ç¡¬ä¸Šé™, å¤š label å¹¶è¡Œ trace, ä» config è¯»å–å‚æ•°ã€‚
        """
        try:
            from ..config import get_soul_config
            cfg = get_soul_config()
            return await asyncio.wait_for(
                self._graph_trace_inner(
                    query, user_id,
                    cfg.graph_max_depth,
                    cfg.graph_trace_timeout_ms / 1000.0,
                ),
                timeout=0.3,  # æ•´ä½“ 300ms ç¡¬ä¸Šé™
            )
        except (asyncio.TimeoutError, Exception):
            return []

    async def _graph_trace_inner(
        self, query: str, user_id: str,
        max_depth: int, trace_timeout: float,
    ) -> List[str]:
        """çŸ¥è¯†å›¾è°±è¿½è¸ªå†…éƒ¨å®ç° â€” å¤š label å¹¶è¡Œ"""
        from ..semantic.knowledge_graph import get_knowledge_graph
        kg = get_knowledge_graph()

        labels = await kg.find_matching_labels(user_id, query, limit=2)
        if not labels:
            return []

        # å¤š label å¹¶è¡Œ trace
        trace_tasks = [
            asyncio.wait_for(
                kg.trace_context(user_id, label, max_depth=max_depth, limit=3),
                timeout=trace_timeout,
            )
            for label in labels
        ]
        all_traces = await asyncio.gather(*trace_tasks, return_exceptions=True)

        results = []
        for t in all_traces:
            if isinstance(t, list):
                results.extend(t)
        return results[:3]

    async def _abstract_recall(self, user_id: str, layer: str) -> List[str]:
        """Phase 3b-beta: æŠ½è±¡è®°å¿†å¬å› â€” æ ¹æ®å±‚çº§æŸ¥è¯¢å‘¨æ‘˜è¦æˆ–äººç”Ÿç« èŠ‚

        L0: ä¸æŸ¥è¯¢æŠ½è±¡å±‚ (é»˜è®¤ä½¿ç”¨åŸå§‹è®°å¿†)
        L1: æŸ¥è¯¢æœ€è¿‘ 2 ä¸ª WeeklyDigest
        L3: æŸ¥è¯¢è¿›è¡Œä¸­çš„ LifeChapter
        """
        if layer == "L0":
            return []

        try:
            from ..storage.soul_collections import get_collection, WEEKLY_DIGESTS, LIFE_CHAPTERS

            if layer == "L1":
                coll = await get_collection(WEEKLY_DIGESTS)
                if coll is None:
                    return []
                cursor = coll.find(
                    {"user_id": user_id},
                    sort=[("week_start", -1)],
                    limit=2,
                    batch_size=2,
                )
                results = []
                async for doc in cursor:
                    summary = doc.get("summary", "")
                    events = doc.get("key_events", [])
                    if summary:
                        week = doc.get("week_start")
                        week_str = week.strftime("%m/%d") if isinstance(week, datetime) else ""
                        entry = f"[{week_str}å‘¨] {summary}"
                        if events:
                            entry += f" (å…³é”®: {'ã€'.join(events[:3])})"
                        results.append(entry)
                return results

            elif layer == "L3":
                coll = await get_collection(LIFE_CHAPTERS)
                if coll is None:
                    return []
                cursor = coll.find(
                    {"user_id": user_id, "ended_at": None},  # è¿›è¡Œä¸­çš„ç« èŠ‚
                    sort=[("started_at", -1)],
                    limit=1,
                    batch_size=1,
                )
                results = []
                async for doc in cursor:
                    title = doc.get("title", "")
                    arc = doc.get("emotional_arc", "")
                    moments = doc.get("defining_moments", [])
                    lessons = doc.get("lessons_learned", [])
                    if title:
                        entry = f"[äººç”Ÿé˜¶æ®µ] {title}"
                        if arc:
                            entry += f" â€” æƒ…ç»ªå¼§çº¿: {arc}"
                        if moments:
                            entry += f" (å…³é”®æ—¶åˆ»: {'ã€'.join(moments[:2])})"
                        if lessons:
                            entry += f" (çµçš„æ„Ÿæ‚Ÿ: {'ã€'.join(lessons[:2])})"
                        results.append(entry)
                return results

        except Exception as e:
            logger.debug(f"[Soul] Abstract recall failed: {e}")

        return []

    async def _collective_wisdom(
        self, query: str, emotion_hint: Optional[str],
    ) -> List[str]:
        """Phase 4: é›†ä½“æ™ºæ…§ â€” ä»åŒ¿åæ¨¡å¼åº“ä¸­åŒ¹é…å½“å‰æƒ…å¢ƒ"""
        try:
            from ..collective.wisdom_retriever import retrieve_wisdom
            return await asyncio.wait_for(
                retrieve_wisdom(emotion_hint=emotion_hint, query=query, limit=2),
                timeout=0.3,
            )
        except Exception as e:
            logger.debug(f"[Soul] Collective wisdom failed: {e}")
            return []

    async def _graphiti_search(
        self, query: str, user_id: str, top_k: int,
    ) -> List[str]:
        """SOTA: Graphiti æ—¶åºçŸ¥è¯†å›¾è°±æœç´¢ (ç¬¬ 8 è·¯æ›¿æ¢)

        é€šè¿‡ GraphitiAdapter æœç´¢, è¿”å›å¸¦æ—¶åºä¸Šä¸‹æ–‡çš„å…³ç³»é“¾ã€‚
        Graphiti ä¸å¯ç”¨æ—¶è¿”å›ç©º (æ—§ graph_trace ä½œä¸º fallback)ã€‚
        """
        try:
            from ..config import get_soul_config
            cfg = get_soul_config()
            if not cfg.graphiti_enabled:
                return []

            from ..adapters.graphiti_adapter import get_graphiti_adapter
            adapter = get_graphiti_adapter()
            results = await asyncio.wait_for(
                adapter.search(query, user_id, top_k=top_k),
                timeout=cfg.graphiti_timeout_ms / 1000.0,
            )
            return [r.content for r in results if r.content]
        except Exception as e:
            logger.debug(f"[Soul] Graphiti search failed: {e}")
            return []

    async def _mem0_entity_search(
        self, query: str, user_id: str, top_k: int,
    ) -> List[str]:
        """SOTA: Mem0 å®ä½“çº§è®°å¿†æœç´¢ (ç¬¬ 11 è·¯)

        æä¾› Soul System ç¼ºå°‘çš„å®ä½“è®°å¿†:
        - "å°æ˜æ˜¯ç”¨æˆ·çš„å¤§å­¦åŒå­¦" (ğŸ¤–å¯¹è¯)
        - "ç”¨æˆ·å»å¹´æ¢äº†å·¥ä½œåˆ° Google" (ğŸ’œæƒ…æ„Ÿå®‰å…¨)
        """
        try:
            from ..config import get_soul_config
            cfg = get_soul_config()
            if not cfg.mem0_enabled:
                return []

            from ..adapters.mem0_adapter import get_mem0_adapter
            adapter = get_mem0_adapter()
            results = await asyncio.wait_for(
                adapter.search(query, user_id, top_k=top_k),
                timeout=cfg.mem0_timeout_ms / 1000.0,
            )
            return [r.content for r in results if r.content]
        except Exception as e:
            logger.debug(f"[Soul] Mem0 search failed: {e}")
            return []

    async def _core_blocks_fetch(self, user_id: str) -> List[str]:
        """Phase 1: Letta Core Blocks è·å–ã€‚"""
        try:
            from soul_fabric import get_memory_fabric

            return await get_memory_fabric().fetch_core_blocks(user_id=user_id)
        except Exception as e:
            logger.debug(f"[Soul] Core blocks fetch failed: {e}")
            return []

    async def _procedural_fetch(self, user_id: str) -> List[str]:
        """Phase 1: LangMem ç¨‹åºæ€§è®°å¿†è·å–ã€‚"""
        try:
            from soul_fabric import get_memory_fabric

            return await get_memory_fabric().fetch_procedural_rules(user_id=user_id)
        except Exception as e:
            logger.debug(f"[Soul] Procedural memory fetch failed: {e}")
            return []

    async def _safety_shadow_fetch(self, user_id: str) -> List[str]:
        """Phase 2: å®‰å…¨å½±å­è®°å¿†æé†’ã€‚"""
        try:
            from soul_fabric import get_memory_fabric

            return await get_memory_fabric().fetch_safety_alerts(user_id=user_id)
        except Exception as e:
            logger.debug(f"[Soul] Safety shadow fetch failed: {e}")
            return []

    async def _life_context(self, user_id: str) -> tuple:
        """Phase 4: è·å–å½“å‰äººç”Ÿç« èŠ‚ + æƒ…æ„ŸåŸºçº¿

        Returns:
            (current_life_chapter: Optional[str], emotional_baseline: str)
        """
        chapter = None
        baseline = "neutral"
        try:
            from ..storage.soul_collections import get_collection, LIFE_CHAPTERS, EMOTIONS
            # å½“å‰äººç”Ÿç« èŠ‚
            lc_coll = await get_collection(LIFE_CHAPTERS)
            if lc_coll is not None:
                doc = await lc_coll.find_one(
                    {"user_id": user_id, "ended_at": None},
                    sort=[("started_at", -1)],
                )
                if doc:
                    title = doc.get("title", "")
                    theme = doc.get("theme", "")
                    chapter = f"{title}" + (f" â€” {theme}" if theme else "")

            # æƒ…æ„ŸåŸºçº¿: è¿‘ 30 å¤©æœ€å¸¸è§æƒ…ç»ª
            em_coll = await get_collection(EMOTIONS)
            if em_coll is not None:
                from datetime import timedelta
                cutoff = datetime.now(timezone.utc) - timedelta(days=30)
                pipeline = [
                    {"$match": {"user_id": user_id, "created_at": {"$gte": cutoff}}},
                    {"$group": {"_id": "$user_emotion", "count": {"$sum": 1}}},
                    {"$sort": {"count": -1}},
                    {"$limit": 1},
                ]
                async for doc in em_coll.aggregate(pipeline):
                    baseline = doc.get("_id", "neutral") or "neutral"
        except Exception as e:
            logger.debug(f"[Soul] Life context failed: {e}")
        return chapter, baseline

    @staticmethod
    async def _clear_milestone(coll, user_id: str):
        """P2: é‡Œç¨‹ç¢‘ä¸€æ¬¡æ€§æ¶ˆè´¹ â€” è¯»åæ¸…é™¤"""
        try:
            from ..storage.soul_collections import get_collection, RELATIONSHIPS
            if coll is None:
                coll = await get_collection(RELATIONSHIPS)
            if coll is None:
                return
            await coll.update_one(
                {"user_id": user_id},
                {"$set": {"recent_milestone": None}},
            )
        except Exception:
            pass  # fire-and-forget

    @staticmethod
    async def _bump_recall_count(user_id: str):
        """v3: å¼‚æ­¥æ›´æ–°æœ€è¿‘ä¸€æ¡ importance çš„ recall_count + last_recalled_at"""
        try:
            from ..storage.soul_collections import get_collection, IMPORTANCE
            coll = await get_collection(IMPORTANCE)
            if coll is None:
                return
            await coll.find_one_and_update(
                {"user_id": user_id},
                {
                    "$inc": {"recall_count": 1},
                    "$set": {"last_recalled_at": datetime.now(timezone.utc)},
                },
                sort=[("created_at", -1)],
            )
        except Exception:
            pass  # fire-and-forget

    @staticmethod
    def _within_days(timestamp_str: str, days: int) -> bool:
        """æ£€æŸ¥ ISO æ—¶é—´æˆ³æ˜¯å¦åœ¨æœ€è¿‘ N å¤©å†…"""
        try:
            ts = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
            return (datetime.now(timezone.utc) - ts).days <= days
        except (ValueError, TypeError):
            return False

    async def _fetch_relationship(self, user_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å…³ç³»é˜¶æ®µ + breakthrough_hint é—­ç¯"""
        try:
            from ..storage.soul_collections import get_collection, RELATIONSHIPS
            coll = await get_collection(RELATIONSHIPS)
            if coll is None:
                return None

            doc = await coll.find_one({"user_id": user_id})
            if doc:
                # v3: åˆ†é˜¶æ®µå…³ç³»å†·å´
                last_interaction = doc.get("last_interaction")
                stage_locked_by_cooling = False
                if last_interaction:
                    if isinstance(last_interaction, str):
                        last_interaction = datetime.fromisoformat(last_interaction)
                    days_since = (datetime.now(timezone.utc) - last_interaction).days
                    stage = doc.get("stage", "stranger")
                    cooling_result = check_stage_cooling(stage, days_since)
                    if cooling_result:
                        new_stage, _ = cooling_result
                        # é˜¶æ®µé™çº§ + åˆ†æ•°è¡°å‡ â€” fire-and-forget
                        old_score = doc.get("accumulated_score", 0)
                        decay = old_score * COOLING_DECAY_RATE
                        new_score = max(0, old_score - decay)
                        create_logged_task(
                            self._cooling_write(
                                coll,
                                user_id,
                                new_score,
                                new_stage,
                                cooled_from_stage=stage,
                            ),
                            "relationship_cooling_downgrade",
                        )
                        doc["accumulated_score"] = new_score
                        doc["stage"] = new_stage
                        stage_locked_by_cooling = True
                        # Phase 3b: æ ‡è®°å›å½’çŠ¶æ€ä¾› context_builder æ³¨å…¥æ¸©æš–å™äº‹
                        doc["returning_from_absence"] = True
                    elif days_since > COOLING_DAYS:
                        # æœªè¾¾é™çº§é˜ˆå€¼ä½†è¶…è¿‡æœ€ä½å†·å´å¤©æ•° â†’ ä»…åˆ†æ•°è¡°å‡
                        old_score = doc.get("accumulated_score", 0)
                        decay = old_score * COOLING_DECAY_RATE
                        new_score = max(0, old_score - decay)
                        create_logged_task(
                            self._cooling_write(coll, user_id, new_score),
                            "relationship_cooling_decay",
                        )
                        doc["accumulated_score"] = new_score
                        doc["returning_from_absence"] = True

                # Phase 2: breakthrough_hint é—­ç¯ â€” ä» breakthrough_events ç”Ÿæˆ hint
                # ğŸ’œ: çª—å£ä» 7 å¤©æ‰©å¤§åˆ° 30 å¤© (é‡è¦æ—¶åˆ»åº”è¢«è®°ä½æ›´ä¹…)
                # ğŸ¤–: æ–‡æ¡ˆæ”¹ä¸ºè¡Œä¸ºæŒ‡å¯¼è€Œéå…³ç³»æ ‡ç­¾ (show, don't tell)
                breakthroughs = doc.get("breakthrough_events", [])
                if breakthroughs:
                    recent = [b for b in breakthroughs[-5:]
                              if b.get("timestamp") and self._within_days(b["timestamp"], BREAKTHROUGH_WINDOW_DAYS)]
                    if recent:
                        latest = recent[-1]
                        doc["breakthrough_hint"] = (
                            f"ä½ ä»¬ä¹‹é—´æœ‰è¿‡è¿™æ ·çš„æ—¶åˆ»: {latest.get('summary', 'ä¸€æ¬¡æ·±åº¦çš„æƒ…æ„Ÿäº¤æµ')}ã€‚"
                            f"ä½ å¯ä»¥åœ¨åˆé€‚çš„æ—¶å€™æ¸©æŸ”åœ°å¼•ç”¨è¿™æ®µç»å†ã€‚"
                        )

                # è®¡ç®—é˜¶æ®µ
                score = doc.get("accumulated_score", 0)
                total_days = doc.get("total_days_active", 0)
                if not stage_locked_by_cooling:
                    doc["stage"] = _calculate_stage(score, total_days, user_id=user_id)
                return doc

            return None
        except Exception as e:
            logger.debug(f"[Soul] Relationship fetch failed: {e}")
            return None

    @staticmethod
    async def _cooling_write(
        coll, user_id: str, new_score: float, new_stage: Optional[str] = None,
        cooled_from_stage: Optional[str] = None,
    ):
        """å†·å´è¡°å‡å†™å…¥ â€” fire-and-forgetï¼Œå¤±è´¥åª warning"""
        try:
            update = {"accumulated_score": new_score, "cooling_warned": True}
            if new_stage:
                update["stage"] = new_stage
                update["stage_entered_at"] = datetime.now(timezone.utc)
                # P1: å…³ç³»å¼¹æ€§ â€” æ ‡è®°é™çº§æ¥æº
                if cooled_from_stage:
                    update["cooled_from_stage"] = cooled_from_stage
                    update["cooled_at"] = datetime.now(timezone.utc)
            await coll.update_one(
                {"user_id": user_id},
                {"$set": update},
            )
        except Exception as e:
            logger.warning(f"[Soul] Cooling write failed (non-fatal): {e}")
